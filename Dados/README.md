Conjunto de dados usados nas Simulações, os dados são referentes a pesquisa sobre diabetes e seus efeitos em pacientes realizada por Efron, Bradley & Hastie, Trevor & Johnstone, Iain & Tibshirani, Rob. (2004). Least Angle Regression (with discussions). The Annals of Statistics. 32. 

### Abstract ######
The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a Cp estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.
### Resumo (Tradução Livre) #####
O objetivo dos algoritmos de seleção de modelos, como Todos os Subconjuntos, Seleção Avançada e Eliminação Retroativa, é escolher um modelo linear com base no mesmo conjunto de dados ao qual o modelo será aplicado. Tipicamente, temos disponível uma grande coleção de possíveis covariáveis das quais esperamos selecionar um conjunto parcimonioso para a predição eficiente de uma variável de resposta. A Regressão de Menor Ângulo (LARS), um novo algoritmo de seleção de modelo, é uma versão útil e menos ávida dos métodos tradicionais de seleção avançada. Três propriedades principais são derivadas: (1) Uma modificação simples do algoritmo LARS implementa o Lasso, uma versão atrativa dos mínimos quadrados ordinários que restringe a soma dos coeficientes de regressão absolutos; a modificação do LARS calcula todas as possíveis estimativas de Lasso para um problema dado, usando uma ordem de magnitude menos tempo de computador do que métodos anteriores. (2) Uma modificação diferente do LARS implementa eficientemente a regressão linear Forward Stagewise, outro método de seleção de modelo promissor; essa conexão explica os resultados numéricos semelhantes anteriormente observados para o Lasso e Stagewise, e nos ajuda a entender as propriedades de ambos os métodos, que são vistos como versões restritas do algoritmo LARS mais simples. (3) Uma simples aproximação para os graus de liberdade de uma estimativa do LARS está disponível, a partir da qual derivamos uma estimativa de erro de predição Cp; isso permite uma escolha fundamentada entre o conjunto de possíveis estimativas do LARS. O LARS e suas variantes são computacionalmente eficientes: o artigo descreve um algoritmo publicamente disponível que requer apenas a mesma ordem de magnitude de esforço computacional do que mínimos quadrados ordinários aplicados ao conjunto completo de covariáveis.
